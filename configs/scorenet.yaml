data: 
  numeric: [
    "limit_bal", 
    "age", 
    "pay_0", 
    "pay_2", 
    "pay_3", 
    "pay_4", 
    "pay_5", 
    "pay_6", 
    "bill_amt1", 
    "bill_amt2", 
    "bill_amt3", 
    "bill_amt4", 
    "bill_amt5", 
    "bill_amt6", 
    "pay_amt1",
    "pay_amt2", 
    "pay_amt3", 
    "pay_amt4", 
    "pay_amt5", 
    "pay_amt6"
  ]
  category: [
    "default_payment_next_month",
    "sex", 
    "education", 
    "marriage"
  ]
  target: default_payment_next_month 
  target_class: 1
  classification: true
  test_prop: .2
  batch_size: 64
  logit_transform: false
model: 
  input_layer: 
    [
      [Linear, 30, 1024],     # number of input features
      [LayerNorm, 1024],
      # [Dropout, 0.3], 
      [ELU]
    ]
  hidden_layers: 
    [
      [Linear, 1024, 1024], 
      [LayerNorm, 1024],
      # [Dropout, 0.2], 
      [ELU],
      [Linear, 1024, 512], 
      [LayerNorm, 512],
      # [Dropout, 0.1], 
      [ELU]
    ]
  output_layer:
    [
      [Linear, 512, 30],       # number of input features
      [LayerNorm, 30]      
    ]       
training: 
  algo: "ssm"                
  noise_std: .1                # dsm
  n_particles: 1               # ssm
  n_epochs: 1000
  snapshot_freq: 3750
  n_steps_min: 3750
  eval_freq: 375
  n_steps_no_improvement: 5
  resume_training: false
optim:
  optimizer: 
    weight_decay: 0.000
    name: "Adam"
    lr: 0.001
    beta1: 0.9
  scheduler: 
    name: ExponentialLR
    gamma: .9
  use_scheduler: false
sampling: 
  n_steps: 1000
  step_lr: 0.00002
  n_batches: 3
  burn_in: .7                  # proportion of mcmc samples to burn 
  strategy: mean               # average or all or median
backup: 
  save: true
  dir: backup/taiwan_payment/scorenet/dsm2
  checkpoint: -1
device: cpu
mode: eval